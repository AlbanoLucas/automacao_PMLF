from imports import *
from celery_config import app
from openai import OpenAI

PASTA_PDFS = r"C:\\Users\\aesouza\\Desktop\\projetos_engenharia_ambiental"

client = OpenAI(
    api_key="ollama",
    base_url="http://localhost:11434/v1"
)

def consultar_llm(prompt):
    """
    Fun√ß√£o para interagir com o modelo LLaMA e obter respostas baseadas no conte√∫do do PDF.
    O prompt √© ajustado para que o modelo se comporte como um especialista em projetos de engenharia ambiental.
    """
    try:
        resposta = client.chat.completions.create(
            model="llama3:8b",
            messages=[
                {"role": "system", "content": "Voc√™ √© um especialista em engenharia ambiental, com experi√™ncia em projetos e regulamenta√ß√µes. Extraia dados importantes e resuma informa√ß√µes t√©cnicas dos documentos."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        return resposta.choices[0].message.content
    except Exception as e:
        return f"Erro ao consultar LLM local: {e}"

def extrair_texto_pdf(caminho_pdf):
    """
    Fun√ß√£o para extrair o texto do PDF usando pdfplumber.
    Retorna o texto extra√≠do de todas as p√°ginas do PDF.
    """
    texto = ""
    with pdfplumber.open(caminho_pdf) as pdf:
        for page in pdf.pages:
            pagina = page.extract_text()
            if pagina:
                texto += pagina + "\n"
    return texto

def processar_projetos_com_llm():
    """
    Fun√ß√£o para processar os PDFs da pasta especificada. Para cada PDF, extrai-se o texto
    e consulta-se o LLaMA para obter um resumo t√©cnico com dados importantes de projetos de engenharia ambiental.
    """
    resultados = []
    for arquivo in os.listdir(PASTA_PDFS):
        if arquivo.lower().endswith(".pdf"):
            caminho = os.path.join(PASTA_PDFS, arquivo)
            print(f"üßæ Processando: {arquivo}")
            texto = extrair_texto_pdf(caminho)
            
            # Consultando o LLaMA com o texto extra√≠do do PDF
            prompt = f"Leia o seguinte conte√∫do de um projeto de engenharia ambiental e forne√ßa um resumo t√©cnico com todos os dados importantes:\n\n{texto}"
            resposta = consultar_llm(prompt)
            
            print(f"‚úÖ Resultado:\n{resposta}")
            resultados.append(f"üìÑ {arquivo}\n{resposta}")
    return resultados

# Execu√ß√£o do processamento
resultados = processar_projetos_com_llm()
print("Processamento conclu√≠do.\n", resultados)
